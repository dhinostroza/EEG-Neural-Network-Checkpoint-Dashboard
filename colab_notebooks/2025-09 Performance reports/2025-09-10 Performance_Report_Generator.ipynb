{"cells":[{"cell_type":"code","source":["# ==============================================================================\n","# SCRIPT TO GENERATE FINAL PERFORMANCE REPORT (CACHE FIX)\n","# This version corrects the CombinedDataset to use in-memory caching,\n","# resolving the extreme performance bottleneck.\n","# ==============================================================================\n","\n","import os\n","import sys\n","from google.colab import auth, drive\n","\n","# --- 1. SETUP THE COLAB ENVIRONMENT ---\n","print(\"--- Step 1: Preparing the main Colab environment ---\")\n","try:\n","    auth.authenticate_user()\n","    print(\"âœ… Authentication successful.\")\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\"âœ… Google Drive mounted successfully.\")\n","except Exception as e:\n","    sys.exit(f\"âŒ FATAL ERROR: Could not set up environment. Details: {e}\")\n","\n","# --- CONFIGURATION (UPDATE THIS) ---\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/final_model_checkpoint/best-model-20250908_233138_convnext_base_2000files_Augmented_cwN1-6.5.ckpt\"\n","\n","# --- Pre-flight check to validate the checkpoint path ---\n","print(\"\\n--- Step 2: Validating checkpoint path ---\")\n","if not os.path.exists(CHECKPOINT_PATH):\n","    print(f\"âŒ FATAL ERROR: Checkpoint file not found at the specified path.\")\n","    sys.exit(f\"Path not found: {CHECKPOINT_PATH}\")\n","else:\n","    print(f\"âœ… Checkpoint file found: {os.path.basename(CHECKPOINT_PATH)}\")\n","\n","\n","# --- 2. CREATE AND PROVISION THE ISOLATED REPORTING ENVIRONMENT ---\n","print(\"\\n--- Step 3: Creating and provisioning the isolated reporting environment ---\")\n","!pip install --upgrade -q virtualenv\n","!virtualenv report_env\n","!report_env/bin/pip install --upgrade -q pip \"pytorch-lightning\" \"timm\" \"pandas>=2.0\" \"pyarrow>=15.0\" \"fsspec>=2023.6.0\" gcsfs google-auth matplotlib seaborn scikit-learn\n","print(\"âœ… All dependencies installed successfully into 'report_env'.\")\n","\n","\n","# --- 3. CREATE AND RUN THE REPORTING LOGIC SCRIPT ---\n","print(\"\\n--- Step 4: Preparing and executing the reporting logic ---\")\n","\n","python_script_logic = f'''\n","import matplotlib\n","matplotlib.use('Agg')\n","import torch\n","import torch.nn as nn\n","import timm\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pytorch_lightning as pl\n","from torchmetrics.classification import MulticlassConfusionMatrix\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import classification_report\n","\n","torch.set_float32_matmul_precision('medium')\n","\n","# --- CONFIGURATION ---\n","CHECKPOINT_PATH = \"{CHECKPOINT_PATH}\"\n","GCS_MANIFEST_PATH = \"gs://shhs-sleepedfx-data-bucket/metadata/shhs_dataset_manifest.csv\"\n","NUM_FILES_TO_USE = 2000\n","BATCH_SIZE = 256\n","NUM_WORKERS = 2\n","\n","# --- DEFINITIONS (Must match the training script) ---\n","def get_model(model_name='convnext_base', pretrained=False):\n","    model = timm.create_model('convnextv2_base.fcmae_ft_in22k_in1k', pretrained=pretrained)\n","    original_conv = model.stem[0]\n","    new_first_conv = nn.Conv2d(1, original_conv.out_channels, kernel_size=original_conv.kernel_size, stride=original_conv.stride, padding=original_conv.padding, bias=(original_conv.bias is not None))\n","    with torch.no_grad():\n","        if original_conv.weight.shape[1] == 3:\n","            new_first_conv.weight[:, :] = original_conv.weight.clone().mean(dim=1, keepdim=True)\n","    model.stem[0] = new_first_conv\n","    num_ftrs = model.head.fc.in_features\n","    model.head.fc = nn.Linear(num_ftrs, 5)\n","    return model\n","\n","class SleepStageClassifierLightning(pl.LightningModule):\n","    def __init__(self, model_name='convnext_base', learning_rate=2e-5, class_weights=None, epochs=40):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = get_model(model_name=self.hparams.model_name)\n","        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float) if class_weights else None)\n","    def forward(self, x): return self.model(x)\n","    def normalize_on_gpu(self, x):\n","        mean = torch.mean(x, dim=(1, 2, 3), keepdim=True)\n","        std = torch.std(x, dim=(1, 2, 3), keepdim=True)\n","        return (x - mean) / (std + 1e-6)\n","\n","class CombinedDataset(Dataset):\n","    # --- MODIFICATION: Restored the essential in-memory cache ---\n","    def __init__(self, manifest_path, num_files=None):\n","        manifest_df = pd.read_csv(manifest_path)\n","        if num_files: manifest_df = manifest_df.head(num_files)\n","        self.file_paths = manifest_df['file_path'].tolist()\n","        self.cumulative_epochs = np.cumsum(manifest_df['epoch_count'].values)\n","        self.total_epochs = self.cumulative_epochs[-1]\n","        self._cache = {{}} # The cache is essential for performance\n","\n","    def __len__(self): return self.total_epochs\n","\n","    def __getitem__(self, idx):\n","        file_idx = np.searchsorted(self.cumulative_epochs, idx, side='right')\n","        local_idx = idx - (self.cumulative_epochs[file_idx - 1] if file_idx > 0 else 0)\n","        file_path = self.file_paths[file_idx]\n","\n","        # This logic ensures each worker only reads a file from GCS ONCE.\n","        if file_path not in self._cache:\n","            df = pd.read_parquet(file_path)\n","            self._cache[file_path] = df[df['label'].isin([0, 1, 2, 3, 4])].reset_index(drop=True)\n","\n","        row = self._cache[file_path].iloc[local_idx]\n","        label = np.int64(row['label'])\n","        spectrogram_flat = row.drop('label').values.astype(np.float32)\n","        spectrogram_2d = spectrogram_flat.reshape(1, 76, 60)\n","        return torch.from_numpy(spectrogram_2d), torch.tensor(label)\n","\n","# --- MAIN EXECUTION ---\n","if __name__ == \"__main__\":\n","    print(f\"ðŸ§  Evaluating model from: {os.path.basename(CHECKPOINT_PATH)}\")\n","\n","    print(\"\\\\n--- Loading and splitting dataset from GCS ---\")\n","    full_dataset = CombinedDataset(GCS_MANIFEST_PATH, num_files=NUM_FILES_TO_USE)\n","    torch.manual_seed(42)\n","    train_size = int(0.8 * len(full_dataset))\n","    val_size = len(full_dataset) - train_size\n","    _, val_dataset = random_split(full_dataset, [train_size, val_size])\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n","    print(\"âœ… Validation data is ready.\")\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    save_dir = os.path.dirname(CHECKPOINT_PATH)\n","    exp_name = Path(CHECKPOINT_PATH).stem.replace('best-model-', '')\n","\n","    model = SleepStageClassifierLightning.load_from_checkpoint(checkpoint_path=CHECKPOINT_PATH)\n","    model.to(device)\n","    model.eval()\n","\n","    print(\"\\\\n--- Generating Final Performance Metrics (this may take a few minutes)... ---\")\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for i, (x, y) in enumerate(val_loader):\n","            print(f\"\\\\r  -> Predicting on batch {{i+1}}/{{len(val_loader)}}\", end=\"\")\n","            x_normalized = model.normalize_on_gpu(x.to(device))\n","            logits = model(x_normalized)\n","            all_preds.append(torch.argmax(logits, dim=1).cpu())\n","            all_labels.append(y.cpu())\n","    print(\"\\\\n  -> Prediction complete.\")\n","\n","    all_preds = torch.cat(all_preds).numpy()\n","    all_labels = torch.cat(all_labels).numpy()\n","    stage_map = {{0: \"Wake\", 1: \"N1\", 2: \"N2\", 3: \"N3\", 4: \"REM\"}}\n","    target_names = [stage_map[i] for i in range(5)]\n","\n","    print(\"\\\\n\" + \"=\"*80)\n","    print(\"--- Detailed Classification Report ---\")\n","    report = classification_report(all_preds, all_labels, target_names=target_names, digits=4)\n","    print(report)\n","    print(\"=\"*80)\n","\n","    print(\"\\\\n--- Generating Confusion Matrix Heatmap ---\")\n","    matrix = MulticlassConfusionMatrix(num_classes=5)(torch.tensor(all_preds), torch.tensor(all_labels)).numpy()\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n","    plt.title(f'Confusion Matrix\\\\n({{exp_name}})', fontsize=16)\n","    plt.ylabel('True Label'); plt.xlabel('Predicted Label')\n","    save_path = os.path.join(save_dir, f\"{{exp_name}}_confusion_matrix.png\")\n","    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n","    print(f\"âœ… Confusion matrix plot saved to: {{save_path}}\")\n","'''\n","\n","# Write the script to a file\n","with open(\"run_report.py\", \"w\") as f:\n","    f.write(python_script_logic)\n","\n","# Execute the script using the virtual environment's python, forcing the correct backend\n","!MPLBACKEND=Agg report_env/bin/python run_report.py\n","\n","print(\"\\n--- Script execution finished. ---\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["--- Step 1: Preparing the main Colab environment ---\n","âœ… Authentication successful.\n","Mounted at /content/drive\n","âœ… Google Drive mounted successfully.\n","\n","--- Step 2: Validating checkpoint path ---\n","âœ… Checkpoint file found: best-model-20250908_233138_convnext_base_2000files_Augmented_cwN1-6.5.ckpt\n","\n","--- Step 3: Creating and provisioning the isolated reporting environment ---\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hcreated virtual environment CPython3.12.11.final.0-64 in 240ms\n","  creator CPython3Posix(dest=/content/report_env, clear=False, no_vcs_ignore=False, global=False)\n","  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n","    added seed packages: pip==25.2\n","  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n","âœ… All dependencies installed successfully into 'report_env'.\n","\n","--- Step 4: Preparing and executing the reporting logic ---\n","ðŸ§  Evaluating model from: best-model-20250908_233138_convnext_base_2000files_Augmented_cwN1-6.5.ckpt\n","\n","--- Loading and splitting dataset from GCS ---\n","âœ… Validation data is ready.\n","\n","--- Generating Final Performance Metrics (this may take a few minutes)... ---\n","  -> Predicting on batch 1565/1565\n","  -> Prediction complete.\n","\n","================================================================================\n","--- Detailed Classification Report ---\n","              precision    recall  f1-score   support\n","\n","        Wake     0.8284    0.9543    0.8869    100281\n","          N1     0.6906    0.1710    0.2741     60705\n","          N2     0.6632    0.9023    0.7645    122468\n","          N3     0.8949    0.6713    0.7672     66033\n","         REM     0.6866    0.7239    0.7047     51116\n","\n","    accuracy                         0.7437    400603\n","   macro avg     0.7527    0.6845    0.6795    400603\n","weighted avg     0.7499    0.7437    0.7136    400603\n","\n","================================================================================\n","\n","--- Generating Confusion Matrix Heatmap ---\n","âœ… Confusion matrix plot saved to: /content/drive/MyDrive/final_model_checkpoint/20250908_233138_convnext_base_2000files_Augmented_cwN1-6.5_confusion_matrix.png\n","\n","--- Script execution finished. ---\n"]}],"execution_count":1,"metadata":{"id":"-dBTavUln5B7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757601667139,"user_tz":300,"elapsed":16919876,"user":{"displayName":"Daniel Hinostroza","userId":"01416331706775365219"}},"outputId":"6348bc09-c7bb-4fd0-a40b-8197dc8c14e9"}}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}