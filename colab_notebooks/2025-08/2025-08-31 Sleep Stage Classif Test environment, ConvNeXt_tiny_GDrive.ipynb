{"cells":[{"cell_type":"code","source":["# Cell 1: Initial setup, connecting to Google Drive, installing libraries, and checking GPU availability.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Instalar y actualizar las librerÃ­as\n","print(\"\\nInstalando y actualizando librerÃ­as...\")\n","!pip install --upgrade -q mne pytorch-lightning timm\n","print(\"âœ… LibrerÃ­as listas.\")\n","\n","# Step 3: Prueba explÃ­cita de control de la GPU\n","import torch\n","print(\"\\n--- INICIANDO PRUEBA DE CONTROL DE GPU ---\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"âœ… GPU detectada: {torch.cuda.get_device_name(0)}\")\n","    try:\n","        tensor_grande = torch.randn(1024, 1024, 512, device=device) # Asignar 2GB\n","        memoria_asignada = torch.cuda.memory_allocated(0) / 1024**3\n","        print(f\"âœ… Â¡Ã‰xito! Memoria asignada activamente: {memoria_asignada:.2f} GB\")\n","        del tensor_grande\n","        torch.cuda.empty_cache()\n","        print(\"âœ… Memoria liberada correctamente.\")\n","        print(\"--- PRUEBA DE CONTROL DE GPU COMPLETADA EXITOSAMENTE ---\")\n","    except Exception as e:\n","        print(f\"âŒ Â¡ERROR DURANTE LA PRUEBA! No se pudo asignar memoria a la GPU: {e}\")\n","else:\n","    print(\"âŒ Â¡ERROR! No se detectÃ³ ninguna GPU en este entorno de ejecuciÃ³n.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WM3gv5-0P2gP","executionInfo":{"status":"ok","timestamp":1756651705720,"user_tz":300,"elapsed":31279,"user":{"displayName":"Daniel Hinostroza","userId":"01416331706775365219"}},"outputId":"20e748f9-47e4-4179-e155-6113058bd3ad"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Instalando y actualizando librerÃ­as...\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hâœ… LibrerÃ­as listas.\n","\n","--- INICIANDO PRUEBA DE CONTROL DE GPU ---\n","âœ… GPU detectada: NVIDIA A100-SXM4-40GB\n","âœ… Â¡Ã‰xito! Memoria asignada activamente: 2.00 GB\n","âœ… Memoria liberada correctamente.\n","--- PRUEBA DE CONTROL DE GPU COMPLETADA EXITOSAMENTE ---\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# 1. SETUP AND DATA PREPARATION\n","# ==============================================================================\n","from google.colab import drive\n","from pathlib import Path\n","import os\n","\n","# Mount Google Drive to access the dataset\n","print(\"Mounting Google Drive...\")\n","drive.mount('/content/drive', force_remount=True)\n","print(\"âœ… Google Drive mounted.\")\n","\n","# --- MODIFIED: Conditionally copy data to local disk for stability and speed ---\n","# This check prevents re-copying files on every run.\n","local_shhs_dir = Path('/content/local_shhs_data')\n","\n","if local_shhs_dir.exists() and any(local_shhs_dir.glob('**/*.parquet')):\n","    print(f\"\\nâœ… Data already exists in {local_shhs_dir}. Skipping file copy.\")\n","else:\n","    print(f\"\\nLocal data not found. Copying dataset from Google Drive...\")\n","\n","    # Define source directories on Google Drive\n","    gdrive_shhs1_dir = Path('/content/drive/MyDrive/shhs1_processed')\n","    gdrive_shhs2_dir = Path('/content/drive/MyDrive/shhs2_processed')\n","\n","    # Define local destination directories in the Colab environment\n","    local_shhs1_dir = local_shhs_dir / 'shhs1'\n","    local_shhs2_dir = local_shhs_dir / 'shhs2'\n","\n","    # Create the local directories\n","    os.makedirs(local_shhs1_dir, exist_ok=True)\n","    os.makedirs(local_shhs2_dir, exist_ok=True)\n","\n","    # Use shell commands to copy the first 100 files from each directory\n","    get_ipython().system(f\"ls -p '{gdrive_shhs1_dir}' | grep -v / | head -n 100 | xargs -I % cp '{gdrive_shhs1_dir}/%' '{local_shhs1_dir}/'\")\n","    get_ipython().system(f\"ls -p '{gdrive_shhs2_dir}' | grep -v / | head -n 100 | xargs -I % cp '{gdrive_shhs2_dir}/%' '{local_shhs2_dir}/'\")\n","\n","    print(\"âœ… Data copying complete.\")\n","\n","# ==============================================================================\n","# 2. DEPENDENCY INSTALLATION\n","# ==============================================================================\n","print(\"\\nEnsuring PyTorch Lightning and other libraries are installed...\")\n","!pip install --upgrade -q pytorch-lightning timm \"pandas==2.2.2\" \"pyarrow==19.0.0\"\n","print(\"âœ… Installation check complete.\")\n","\n","# ==============================================================================\n","# 3. IMPORTS AND INITIAL CONFIGURATION\n","# ==============================================================================\n","import torch\n","import torch.nn as nn\n","import timm\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import CSVLogger\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n","import numpy as np\n","import pandas as pd\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","torch.set_float32_matmul_precision('medium')\n","print(\"âœ… Libraries imported and configuration set.\")\n","\n","# ==============================================================================\n","# 4. MODEL ARCHITECTURE DEFINITION (SINGLE-MODEL)\n","# ==============================================================================\n","def get_model(model_name='convnext_tiny', num_classes=5, pretrained=True):\n","    \"\"\"Creates a ConvNeXT Tiny model adapted for sleep stage classification.\"\"\"\n","    if model_name == 'convnext_tiny':\n","        model = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=pretrained)\n","        original_conv = model.stem[0]\n","        new_first_conv = nn.Conv2d(1, original_conv.out_channels, kernel_size=original_conv.kernel_size, stride=original_conv.stride, padding=original_conv.padding, bias=(original_conv.bias is not None))\n","        with torch.no_grad():\n","            if original_conv.weight.shape[1] == 3:\n","                new_first_conv.weight[:, :] = original_conv.weight.clone().mean(dim=1, keepdim=True)\n","        model.stem[0] = new_first_conv\n","        num_ftrs = model.head.fc.in_features\n","        model.head.fc = nn.Linear(num_ftrs, num_classes)\n","        print(f\"âœ… ConvNeXT Tiny model created.\")\n","    else:\n","        raise ValueError(f\"Model '{model_name}' not supported in this script.\")\n","    return model\n","\n","print(\"âœ… `get_model` function defined for ConvNeXT Tiny.\")\n","\n","# ==============================================================================\n","# 5. PYTORCH LIGHTNING MODULE\n","# ==============================================================================\n","class SleepStageClassifierLightning(pl.LightningModule):\n","    def __init__(self, model_name, learning_rate=1e-5, class_weights=None):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = get_model(model_name=self.hparams.model_name, num_classes=5, pretrained=True)\n","        self.train_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.val_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float) if class_weights is not None else None)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y_true = batch\n","        y_pred_logits = self(x)\n","        loss = self.loss_fn(y_pred_logits, y_true)\n","        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_acc', self.train_accuracy(y_pred_logits, y_true), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y_true = batch\n","        y_pred_logits = self(x)\n","        loss = self.loss_fn(y_pred_logits, y_true)\n","        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', self.val_accuracy(y_pred_logits, y_true), on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n","        scheduler = {'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3), 'monitor': 'val_loss'}\n","        return [optimizer], [scheduler]\n","\n","print(\"âœ… `SleepStageClassifierLightning` module defined.\")\n","\n","# ==============================================================================\n","# 6. CUSTOM DATASET DEFINITION\n","# ==============================================================================\n","class CombinedDataset(Dataset):\n","    def __init__(self, file_paths_chunk):\n","        print(f\"Initializing dataset with {len(file_paths_chunk)} files...\")\n","        self.file_paths = file_paths_chunk\n","        self.epochs_per_file = [pd.read_parquet(f, columns=['label'])['label'].isin([0, 1, 2, 3, 4]).sum() for f in self.file_paths]\n","        self.cumulative_epochs = np.cumsum(self.epochs_per_file)\n","        self.total_epochs = self.cumulative_epochs[-1] if self.cumulative_epochs.size > 0 else 0\n","        self._cache = {}\n","        print(f\"âœ… Dataset initialized. Total valid epochs: {self.total_epochs}\")\n","\n","    def __len__(self):\n","        return self.total_epochs\n","\n","    def __getitem__(self, idx):\n","        file_idx = np.searchsorted(self.cumulative_epochs, idx, side='right')\n","        local_idx = idx - (self.cumulative_epochs[file_idx - 1] if file_idx > 0 else 0)\n","        file_path = self.file_paths[file_idx]\n","        if file_path not in self._cache:\n","            df = pd.read_parquet(file_path)\n","            self._cache[file_path] = df[df['label'].isin([0, 1, 2, 3, 4])].reset_index(drop=True)\n","        row = self._cache[file_path].iloc[local_idx]\n","        label = np.int64(row['label'])\n","        spectrogram_flat = row.drop('label').values.astype(np.float32)\n","        mean, std = spectrogram_flat.mean(), spectrogram_flat.std()\n","        spectrogram_normalized = (spectrogram_flat - mean) / (std + 1e-6)\n","        spectrogram_2d = spectrogram_normalized.reshape(1, 76, 60)\n","        return torch.from_numpy(spectrogram_2d), torch.tensor(label)\n","\n","print(\"âœ… `CombinedDataset` class defined.\")\n","\n","# ==============================================================================\n","# 7. PERFORMANCE REPORTING FUNCTION\n","# ==============================================================================\n","def generate_performance_report(model_checkpoint_path, dataloader, device):\n","    \"\"\"Loads the best model and generates a detailed classification report.\"\"\"\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"Generating Final Performance Metrics on the Validation Set...\")\n","    model = SleepStageClassifierLightning.load_from_checkpoint(model_checkpoint_path)\n","    model.to(device)\n","    model.eval()\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            logits = model(x.to(device))\n","            all_preds.append(torch.argmax(logits, dim=1).cpu())\n","            all_labels.append(y.cpu())\n","    all_preds = torch.cat(all_preds)\n","    all_labels = torch.cat(all_labels)\n","\n","    num_classes = 5\n","    metrics = {\n","        \"Precision\": MulticlassPrecision(num_classes=num_classes, average=None),\n","        \"Recall\": MulticlassRecall(num_classes=num_classes, average=None),\n","        \"F1-Score\": MulticlassF1Score(num_classes=num_classes, average=None)\n","    }\n","    results = {name: metric(all_preds, all_labels) for name, metric in metrics.items()}\n","    accuracy = MulticlassAccuracy(num_classes=num_classes, average='micro')(all_preds, all_labels)\n","\n","    stage_map = {0: \"Wake\", 1: \"N1\", 2: \"N2\", 3: \"N3\", 4: \"REM\"}\n","    print(\"\\n--- Sleep Stage Classification Report (Best Model) ---\")\n","    print(f\"{'Stage':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n","    print(\"-\" * 50)\n","    for i in range(num_classes):\n","        print(f\"{stage_map[i]:<10} | {results['Precision'][i]:<10.4f} | {results['Recall'][i]:<10.4f} | {results['F1-Score'][i]:<10.4f}\")\n","    print(\"-\" * 50)\n","    print(f\"\\nOverall Accuracy: {accuracy.item():.4f}\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","print(\"âœ… `generate_performance_report` function defined.\")\n","\n","# ==============================================================================\n","# 8. TRAINING EXECUTION\n","# ==============================================================================\n","print(\"\\n--- Starting Model Training ---\")\n","\n","# --- General Parameters ---\n","MODEL_TO_TEST = 'convnext_tiny'\n","EPOCHS = 40\n","BATCH_SIZE = 256\n","NUM_WORKERS = os.cpu_count()\n","CLASS_WEIGHTS = [0.7, 3.5, 0.5, 1.5, 1.2]\n","LEARNING_RATE = 5e-5\n","\n","# --- Paths point to the local Colab directories ---\n","shhs1_processed_dir_base = Path('/content/local_shhs_data/shhs1')\n","shhs2_processed_dir_base = Path('/content/local_shhs_data/shhs2')\n","\n","specific_shhs_file_paths = list(shhs1_processed_dir_base.glob('*.parquet')) + list(shhs2_processed_dir_base.glob('*.parquet'))\n","\n","# --- Main Experiment ---\n","if not specific_shhs_file_paths:\n","     print(\"\\nERROR: No .parquet files found. Aborting.\")\n","else:\n","    print(f\"\\nFound {len(specific_shhs_file_paths)} files for training.\")\n","    full_dataset = CombinedDataset(specific_shhs_file_paths)\n","\n","    if len(full_dataset) > 1:\n","        train_size = int(0.8 * len(full_dataset))\n","        val_size = len(full_dataset) - train_size\n","        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n","        print(f\"Dataset split: {len(train_dataset)} training, {len(val_dataset)} validation.\")\n","\n","        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, persistent_workers=bool(NUM_WORKERS))\n","        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, persistent_workers=bool(NUM_WORKERS))\n","\n","        print(f\"\\n{'='*20} STARTING EXPERIMENT FOR MODEL: {MODEL_TO_TEST.upper()} {'='*20}\")\n","        model = SleepStageClassifierLightning(MODEL_TO_TEST, LEARNING_RATE, CLASS_WEIGHTS)\n","\n","        experiment_name = f\"{MODEL_TO_TEST}_local_test\"\n","        csv_logger = CSVLogger(\"/content/drive/MyDrive/sleep_logs/\", name=experiment_name)\n","\n","        checkpoint_callback = ModelCheckpoint(\n","            monitor='val_loss',\n","            dirpath='/content/drive/MyDrive/final_model_checkpoint/',\n","            filename=f\"sleep-stage-{experiment_name}-{{epoch:02d}}-{{val_loss:.4f}}\",\n","            save_top_k=1, mode='min'\n","        )\n","        early_stop_callback = EarlyStopping(monitor='val_loss', patience=7, verbose=True, mode='min')\n","\n","        trainer = pl.Trainer(\n","            max_epochs=EPOCHS, accelerator=\"gpu\", devices=1, logger=csv_logger,\n","            callbacks=[checkpoint_callback, early_stop_callback],\n","            precision=\"bf16-mixed\", gradient_clip_val=1.0\n","        )\n","\n","        print(f\"ðŸš€ Starting model training for {MODEL_TO_TEST.upper()}...\")\n","        trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n","        print(f\"âœ… Training complete for {MODEL_TO_TEST.upper()}!\")\n","\n","        if checkpoint_callback.best_model_path:\n","            print(f\"Best model saved at: {checkpoint_callback.best_model_path}\")\n","            generate_performance_report(checkpoint_callback.best_model_path, val_loader, model.device)\n","        else:\n","            print(\"No checkpoint was saved. Skipping performance report.\")\n","        print(f\"{'='*20} FINISHED EXPERIMENT FOR MODEL: {MODEL_TO_TEST.upper()} {'='*20}\")\n","    else:\n","        print(\"Dataset is too small to split. Aborting.\")\n","\n","print(\"\\n--- Model Training Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nhuX84Jul8R6","outputId":"d60bb468-6486-424d-dc0e-497554792149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Mounted at /content/drive\n","âœ… Google Drive mounted.\n","\n","Local data not found. Copying dataset from Google Drive...\n","^C\n","^C\n","âœ… Data copying complete.\n","\n","Ensuring PyTorch Lightning and other libraries are installed...\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 162, in get_preference\n","    requested_order: Union[int, float] = self._user_requested[identifier]\n","                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'typing-extensions'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n","    requirement_set = resolver.resolve(\n","                      ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n","    result = self._result = resolver.resolve(\n","                            ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n","    state = resolution.resolve(requirements, max_rounds=max_rounds)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 426, in resolve\n","    name = min(unsatisfied_names, key=self._get_preference)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 203, in _get_preference\n","    return self._p.get_preference(\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 170, in get_preference\n","    inferred_depth = min(d for d in parent_depths) + 1.0\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 170, in <genexpr>\n","    inferred_depth = min(d for d in parent_depths) + 1.0\n","                                    ^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 167, in <genexpr>\n","    self._known_depths[parent.name] if parent is not None else 0.0\n","                       ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 383, in name\n","    return self.project_name\n","           ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 379, in project_name\n","    return self.dist.canonical_name\n","           ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 171, in canonical_name\n","    return canonicalize_name(name)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/utils.py\", line 49, in canonicalize_name\n","    value = _canonicalize_regex.sub(\"-\", name).lower()\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n","    return command.main(cmd_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n","    return self._main(args)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n","    return run(options, args)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n","    self._log(CRITICAL, msg, args, **kwargs)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1022, in handle\n","    rv = self.filter(record)\n","         ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 863, in filter\n","    if isinstance(result, LogRecord):\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","^C\n","âœ… Installation check complete.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1KZKGdwh8fGQtT4sFfNR6GIlRKzaliakp","timestamp":1756646030639}],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}