{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNHV+uDZDH8fJ1G0EtZ8cnU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8841492255574e32857bda5015ef3710":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91c3777f28754d1ba74049d5371d3b21","IPY_MODEL_ef12f14512e440669d5560c56c97ae73","IPY_MODEL_0aac5469ca8944d19074140c3ab66f40"],"layout":"IPY_MODEL_4673ef3b30b24f859aebb2d9eb1df623"}},"91c3777f28754d1ba74049d5371d3b21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_323a75c85fdc438785d7cd10c770e2ce","placeholder":"‚Äã","style":"IPY_MODEL_be7d561d36b8495593cca3ec94ebdcaa","value":"model.safetensors:‚Äá100%"}},"ef12f14512e440669d5560c56c97ae73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40f5fe3859e14d639ba6488bee7817a8","max":438134012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82be8b2674114e26a5ad2fc41bab9f46","value":438134012}},"0aac5469ca8944d19074140c3ab66f40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aa113f51d924cff833b24ca60fdae4b","placeholder":"‚Äã","style":"IPY_MODEL_8fba70dd7fce4975bbd37ba257ea2768","value":"‚Äá438M/438M‚Äá[00:01&lt;00:00,‚Äá213MB/s]"}},"4673ef3b30b24f859aebb2d9eb1df623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323a75c85fdc438785d7cd10c770e2ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be7d561d36b8495593cca3ec94ebdcaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40f5fe3859e14d639ba6488bee7817a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82be8b2674114e26a5ad2fc41bab9f46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7aa113f51d924cff833b24ca60fdae4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fba70dd7fce4975bbd37ba257ea2768":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c1662af6e04413dacc5c7d14c391baf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9f188afa5944d9d8b3218803840d89c","IPY_MODEL_4518be4b85014a2f985961f9f28873ed","IPY_MODEL_0986e35e8cb745e2be1215a634be76e4"],"layout":"IPY_MODEL_481741a338a74b2ab3ceb1a035455706"}},"f9f188afa5944d9d8b3218803840d89c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db7daeaef7e84506847d2e4df8f45d24","placeholder":"‚Äã","style":"IPY_MODEL_6c7dbb373e5e4b22a9c93e53eefc99ff","value":"Sanity‚ÄáChecking‚ÄáDataLoader‚Äá0:‚Äá100%"}},"4518be4b85014a2f985961f9f28873ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_77e2d9d247e748ac9e2db1b1593b996e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31a892fbd8b24e61ae069c66e08113a3","value":2}},"0986e35e8cb745e2be1215a634be76e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19eecab9db164d8a9f8aad6afcdbc55d","placeholder":"‚Äã","style":"IPY_MODEL_3afc7d2fd2f24bdab4fb40e07c2f980a","value":"‚Äá2/2‚Äá[07:19&lt;00:00,‚Äá‚Äá0.00it/s]"}},"481741a338a74b2ab3ceb1a035455706":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"db7daeaef7e84506847d2e4df8f45d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c7dbb373e5e4b22a9c93e53eefc99ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e2d9d247e748ac9e2db1b1593b996e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a892fbd8b24e61ae069c66e08113a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19eecab9db164d8a9f8aad6afcdbc55d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3afc7d2fd2f24bdab4fb40e07c2f980a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96cef4facefb4b31af529c64ac233393":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68be8d9796f844a3943bd1c23e92d0ed","IPY_MODEL_63285b755a7e401ebe2063a2b6398688","IPY_MODEL_b411950486d742d7b05fbe7bc9cb9054"],"layout":"IPY_MODEL_f0036b77ef0345d2a63e2c3d4e5c8d65"}},"68be8d9796f844a3943bd1c23e92d0ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5084b98af2ad4e218387563773faa161","placeholder":"‚Äã","style":"IPY_MODEL_337a4f17d8384ea4bc3e7577841ba2e2","value":"Epoch‚Äá11:‚Äá100%"}},"63285b755a7e401ebe2063a2b6398688":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_787cc22998f2444586ebe0e347ff8673","max":3416,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c8d4974e2ad42be97df9c15aade0f53","value":3416}},"b411950486d742d7b05fbe7bc9cb9054":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_973684fb761d46e7a0d3ae47fdeb1946","placeholder":"‚Äã","style":"IPY_MODEL_4f098cefdaf3453cba7431b86277cd86","value":"‚Äá3416/3416‚Äá[1:32:54&lt;00:00,‚Äá‚Äá0.61it/s,‚Äáv_num=2,‚Äátrain_loss_step=0.569,‚Äátrain_acc_step=0.725,‚Äával_loss=0.598,‚Äával_acc=0.741,‚Äátrain_loss_epoch=0.632,‚Äátrain_acc_epoch=0.730]"}},"f0036b77ef0345d2a63e2c3d4e5c8d65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5084b98af2ad4e218387563773faa161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"337a4f17d8384ea4bc3e7577841ba2e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"787cc22998f2444586ebe0e347ff8673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c8d4974e2ad42be97df9c15aade0f53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"973684fb761d46e7a0d3ae47fdeb1946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f098cefdaf3453cba7431b86277cd86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93da494204db4bc1b516bf874db53f4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e539be8c825443d8916d018793a3adc","IPY_MODEL_0677c765e572449589f0d3ded3b13962","IPY_MODEL_f721df26b3204b0c9444e7d78de715d1"],"layout":"IPY_MODEL_8eb5530b48654a788bb6945fcd36f6be"}},"8e539be8c825443d8916d018793a3adc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc060510f14948cdadcf102f6fbdf77d","placeholder":"‚Äã","style":"IPY_MODEL_7dd8b26cc01c4378bf20eade31ad4e2d","value":"Validation‚ÄáDataLoader‚Äá0:‚Äá100%"}},"0677c765e572449589f0d3ded3b13962":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c8f1155e02347d4a4f9470037f4c988","max":854,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f84ec11c9e647d48d3414dbd9ee9a20","value":854}},"f721df26b3204b0c9444e7d78de715d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34b5384c6df44b4a972c5ae8fb088068","placeholder":"‚Äã","style":"IPY_MODEL_1a3064a331de4977b7086bad1f08bd20","value":"‚Äá854/854‚Äá[12:00&lt;00:00,‚Äá‚Äá1.18it/s]"}},"8eb5530b48654a788bb6945fcd36f6be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"bc060510f14948cdadcf102f6fbdf77d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd8b26cc01c4378bf20eade31ad4e2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c8f1155e02347d4a4f9470037f4c988":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f84ec11c9e647d48d3414dbd9ee9a20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34b5384c6df44b4a972c5ae8fb088068":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a3064a331de4977b7086bad1f08bd20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Cell 1: Initial setup, connecting to Google Drive, installing libraries, and checking GPU availability.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Instalar y actualizar las librer√≠as\n","print(\"\\nInstalando y actualizando librer√≠as...\")\n","!pip install --upgrade -q mne pytorch-lightning timm\n","print(\"‚úÖ Librer√≠as listas.\")\n","\n","# Step 3: Prueba expl√≠cita de control de la GPU\n","import torch\n","print(\"\\n--- INICIANDO PRUEBA DE CONTROL DE GPU ---\")\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n","    try:\n","        tensor_grande = torch.randn(1024, 1024, 512, device=device) # Asignar 2GB\n","        memoria_asignada = torch.cuda.memory_allocated(0) / 1024**3\n","        print(f\"‚úÖ ¬°√âxito! Memoria asignada activamente: {memoria_asignada:.2f} GB\")\n","        del tensor_grande\n","        torch.cuda.empty_cache()\n","        print(\"‚úÖ Memoria liberada correctamente.\")\n","        print(\"--- PRUEBA DE CONTROL DE GPU COMPLETADA EXITOSAMENTE ---\")\n","    except Exception as e:\n","        print(f\"‚ùå ¬°ERROR DURANTE LA PRUEBA! No se pudo asignar memoria a la GPU: {e}\")\n","else:\n","    print(\"‚ùå ¬°ERROR! No se detect√≥ ninguna GPU en este entorno de ejecuci√≥n.\")"],"metadata":{"id":"cD0wWVOigybn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756265620982,"user_tz":300,"elapsed":34675,"user":{"displayName":"Daniel Hinostroza","userId":"01416331706775365219"}},"outputId":"48d3d5a6-5bc8-4ccf-9f12-3692412dee8e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Instalando y actualizando librer√≠as...\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m828.2/828.2 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ Librer√≠as listas.\n","\n","--- INICIANDO PRUEBA DE CONTROL DE GPU ---\n","‚úÖ GPU detectada: NVIDIA A100-SXM4-40GB\n","‚úÖ ¬°√âxito! Memoria asignada activamente: 2.00 GB\n","‚úÖ Memoria liberada correctamente.\n","--- PRUEBA DE CONTROL DE GPU COMPLETADA EXITOSAMENTE ---\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# 1. SETUP AND DEPENDENCY INSTALLATION\n","# ==============================================================================\n","print(\"Ensuring PyTorch Lightning and other libraries are installed...\")\n","# Install the necessary libraries with pinned versions to avoid conflicts\n","!pip install --upgrade -q pytorch-lightning timm \"pandas==2.2.2\" \"pyarrow==19.0.0\"\n","print(\"‚úÖ Installation check complete.\")\n","\n","# ==============================================================================\n","# 2. IMPORTS AND INITIAL CONFIGURATION\n","# ==============================================================================\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import CSVLogger\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import os\n","\n","# Set matrix multiplication precision for A100/H100 GPUs for better performance\n","torch.set_float32_matmul_precision('medium')\n","print(\"‚úÖ Libraries imported and configuration set.\")\n","\n","# ==============================================================================\n","# 3. MODEL ARCHITECTURE DEFINITION\n","# ==============================================================================\n","def get_model(model_name='swin_base', num_classes=5, pretrained=True):\n","    \"\"\"\n","    Creates a model adapted for sleep stage classification using timm's built-in helpers.\n","    \"\"\"\n","    if model_name == 'swin_base':\n","        model = timm.create_model(\n","            'swin_base_patch4_window7_224.ms_in22k',\n","            pretrained=pretrained,\n","            num_classes=num_classes,\n","            in_chans=1,\n","            img_size=(76, 60)\n","        )\n","        print(f\"‚úÖ Swin Transformer Base model created.\")\n","    else:\n","        raise ValueError(f\"Model '{model_name}' not supported for this script.\")\n","\n","    return model\n","\n","print(\"‚úÖ `get_model` function defined.\")\n","\n","# ==============================================================================\n","# 4. PYTORCH LIGHTNING MODULE\n","# ==============================================================================\n","class SleepStageClassifierLightning(pl.LightningModule):\n","    def __init__(self, model_name, learning_rate=1e-5, class_weights=None):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = get_model(model_name=self.hparams.model_name, num_classes=5, pretrained=True)\n","        self.train_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.val_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.weights = torch.tensor(class_weights, dtype=torch.float) if class_weights is not None else None\n","        self.loss_fn = F.cross_entropy\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y_true = batch\n","        y_pred_logits = self(x)\n","        loss = self.loss_fn(y_pred_logits, y_true, weight=self.weights.to(self.device) if self.weights is not None else None)\n","        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('train_acc', self.train_accuracy(y_pred_logits, y_true), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y_true = batch\n","        y_pred_logits = self(x)\n","        loss = self.loss_fn(y_pred_logits, y_true, weight=self.weights.to(self.device) if self.weights is not None else None)\n","        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)\n","        self.log('val_acc', self.val_accuracy(y_pred_logits, y_true), on_epoch=True, prog_bar=True, logger=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.learning_rate)\n","        scheduler = {\n","            'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3),\n","            'monitor': 'val_loss',\n","            'interval': 'epoch',\n","            'frequency': 1,\n","        }\n","        return [optimizer], [scheduler]\n","\n","    def on_fit_end(self):\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"Generating Final Performance Metrics on the Validation Set...\")\n","        self.model.eval()\n","        all_preds, all_labels = [], []\n","        if not self.trainer.val_dataloaders:\n","            print(\"Validation dataloader not available. Skipping report generation.\")\n","            return\n","        with torch.no_grad():\n","            for batch in self.trainer.val_dataloaders:\n","                x, y = batch\n","                x = x.to(self.device)\n","                logits = self.model(x)\n","                preds = torch.argmax(logits, dim=1)\n","                all_preds.append(preds.cpu())\n","                all_labels.append(y.cpu())\n","        all_preds = torch.cat(all_preds)\n","        all_labels = torch.cat(all_labels)\n","        num_classes = 5\n","        precision_metric = MulticlassPrecision(num_classes=num_classes, average=None).to(self.device)\n","        recall_metric = MulticlassRecall(num_classes=num_classes, average=None).to(self.device)\n","        f1_metric = MulticlassF1Score(num_classes=num_classes, average=None).to(self.device)\n","        accuracy_metric = MulticlassAccuracy(num_classes=num_classes, average='micro').to(self.device)\n","        precisions = precision_metric(all_preds, all_labels)\n","        recalls = recall_metric(all_preds, all_labels)\n","        f1_scores = f1_metric(all_preds, all_labels)\n","        accuracy = accuracy_metric(all_preds, all_labels)\n","        stage_map = {0: \"Wake\", 1: \"N1\", 2: \"N2\", 3: \"N3\", 4: \"REM\"}\n","        print(\"\\n--- Sleep Stage Classification Report ---\")\n","        print(f\"{'Stage':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n","        print(\"-\" * 50)\n","        for i in range(num_classes):\n","            stage_name = stage_map[i]\n","            precision, recall, f1 = precisions[i].item(), recalls[i].item(), f1_scores[i].item()\n","            print(f\"{stage_name:<10} | {precision:<10.4f} | {recall:<10.4f} | {f1:<10.4f}\")\n","        print(\"-\" * 50)\n","        print(f\"\\nOverall Accuracy: {accuracy.item():.4f}\")\n","        print(\"=\"*80 + \"\\n\")\n","\n","print(\"‚úÖ `SleepStageClassifierLightning` module defined.\")\n","\n","# ==============================================================================\n","# 5. OPTIMIZED CUSTOM DATASET DEFINITION WITH METADATA CACHING\n","# ==============================================================================\n","class OptimizedCombinedDataset(Dataset):\n","    def __init__(self, file_paths, metadata_path):\n","        self.file_paths = file_paths\n","        self.metadata_path = metadata_path\n","        self._cache = {}\n","\n","        # --- MODIFICATION: Incremental and Resumable Scanning ---\n","        processed_files = set()\n","        if os.path.exists(self.metadata_path):\n","            print(f\"Found existing metadata file at {self.metadata_path}. Checking for unscanned files...\")\n","            metadata_df = pd.read_csv(self.metadata_path)\n","            processed_files = set(metadata_df['filepath'].apply(str))\n","\n","        all_file_paths_str = {str(p) for p in self.file_paths}\n","        files_to_scan = [Path(p) for p in all_file_paths_str - processed_files]\n","\n","        if files_to_scan:\n","            print(f\"Found {len(files_to_scan)} new or unscanned files. Scanning in batches...\")\n","\n","            batch_size = 100 # Scan 100 files at a time\n","            for i in range(0, len(files_to_scan), batch_size):\n","                batch_paths = files_to_scan[i:i + batch_size]\n","                print(f\"  -> Scanning batch {i//batch_size + 1}/{-(-len(files_to_scan)//batch_size)}...\")\n","\n","                epoch_data = []\n","                for f_path in batch_paths:\n","                    try:\n","                        df_labels = pd.read_parquet(f_path, columns=['label'])\n","                        num_valid = df_labels['label'].isin([0, 1, 2, 3, 4]).sum()\n","                        epoch_data.append({'filepath': str(f_path), 'epoch_count': num_valid})\n","                    except Exception as e:\n","                        print(f\"    - Warning: Could not process {f_path.name}. Skipping. Error: {e}\")\n","\n","                # Append results of this batch to the metadata file\n","                if epoch_data:\n","                    batch_df = pd.DataFrame(epoch_data)\n","                    # Use append mode and don't write header if file already exists\n","                    batch_df.to_csv(self.metadata_path, mode='a', header=not os.path.exists(self.metadata_path), index=False)\n","                    print(f\"     ‚úÖ Saved progress for {len(batch_paths)} files.\")\n","\n","        print(\"‚úÖ Scan complete. Loading final metadata...\")\n","        final_metadata_df = pd.read_csv(self.metadata_path)\n","        final_metadata_df['filepath'] = final_metadata_df['filepath'].apply(Path)\n","        epoch_counts_map = dict(zip(final_metadata_df['filepath'], final_metadata_df['epoch_count']))\n","        self.epochs_per_file = [epoch_counts_map.get(fp, 0) for fp in self.file_paths]\n","\n","        self.cumulative_epochs = np.cumsum(self.epochs_per_file)\n","        self.total_epochs = self.cumulative_epochs[-1] if len(self.cumulative_epochs) > 0 else 0\n","        print(f\"‚úÖ Dataset initialized. Total valid epochs: {self.total_epochs}\")\n","\n","    def __len__(self):\n","        return self.total_epochs\n","\n","    def __getitem__(self, idx):\n","        file_idx = np.searchsorted(self.cumulative_epochs, idx, side='right')\n","        local_idx = idx - (self.cumulative_epochs[file_idx - 1] if file_idx > 0 else 0)\n","        file_path = self.file_paths[file_idx]\n","        if file_path not in self._cache:\n","            try:\n","                df = pd.read_parquet(file_path)\n","                self._cache[file_path] = df[df['label'].isin([0, 1, 2, 3, 4])].reset_index(drop=True)\n","            except Exception as e:\n","                raise IOError(f\"Error reading file {file_path.name} in __getitem__: {e}\")\n","        row = self._cache[file_path].iloc[local_idx]\n","        label = np.int64(row['label'])\n","        spectrogram_flat = row.drop('label').values.astype(np.float32)\n","        mean, std = spectrogram_flat.mean(), spectrogram_flat.std()\n","        spectrogram_normalized = (spectrogram_flat - mean) / (std + 1e-6)\n","        spectrogram_2d = spectrogram_normalized.reshape(1, 76, 60)\n","        return torch.from_numpy(spectrogram_2d), torch.tensor(label)\n","\n","print(\"‚úÖ `OptimizedCombinedDataset` class defined.\")\n","\n","# ==============================================================================\n","# 6. TRAINING EXECUTION\n","# ==============================================================================\n","print(\"\\n--- Starting Swin Transformer Experiment (1000 Files, Resumable) ---\")\n","\n","# --- General Parameters ---\n","MODEL_TO_TRAIN = 'swin_base'\n","EPOCHS = 40\n","BATCH_SIZE = 256\n","NUM_WORKERS = 0\n","CLASS_WEIGHTS = [0.7, 3.5, 0.5, 1.5, 1.2]\n","LEARNING_RATE = 2e-5\n","\n","# --- Paths and File Identification (using Google Drive) ---\n","shhs1_processed_dir_base = Path('/content/drive/MyDrive/shhs1_processed')\n","shhs2_processed_dir_base = Path('/content/drive/MyDrive/shhs2_processed')\n","METADATA_PATH = Path('/content/drive/MyDrive/dataset_metadata_1000_files.csv')\n","\n","# Using 1000 files for a fair comparison\n","shhs1_files = list(shhs1_processed_dir_base.glob('*.parquet'))[:500]\n","shhs2_files = list(shhs2_processed_dir_base.glob('*.parquet'))[:500]\n","specific_shhs_file_paths = shhs1_files + shhs2_files\n","\n","# --- Main Experiment Logic ---\n","if not specific_shhs_file_paths:\n","     print(\"\\nERROR: No valid .parquet files were found. Aborting experiment.\")\n","else:\n","    print(f\"\\nFound {len(specific_shhs_file_paths)} specific files for training.\")\n","\n","    full_dataset = OptimizedCombinedDataset(\n","        file_paths=specific_shhs_file_paths,\n","        metadata_path=METADATA_PATH\n","    )\n","\n","    if len(full_dataset) > 1:\n","        train_size = int(0.8 * len(full_dataset))\n","        val_size = len(full_dataset) - train_size\n","        train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n","\n","        print(f\"Dataset split: {len(train_dataset)} training samples, {len(val_dataset)} validation samples.\")\n","\n","        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, persistent_workers= (NUM_WORKERS > 0) )\n","        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, persistent_workers= (NUM_WORKERS > 0) )\n","\n","        model = SleepStageClassifierLightning(\n","            model_name=MODEL_TO_TRAIN,\n","            learning_rate=LEARNING_RATE,\n","            class_weights=CLASS_WEIGHTS\n","        )\n","\n","        experiment_name = f\"{MODEL_TO_TRAIN}_1000_files_resumable_lr_2e-5\"\n","        checkpoint_dir = Path('/content/drive/MyDrive/final_model_checkpoint/') / experiment_name\n","        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n","\n","        csv_logger = CSVLogger(\"/content/drive/MyDrive/sleep_logs/\", name=experiment_name)\n","\n","        checkpoint_callback = ModelCheckpoint(\n","            monitor='val_loss',\n","            dirpath=checkpoint_dir,\n","            filename=f\"sleep-stage-model-{{epoch:02d}}-{{val_loss:.4f}}\",\n","            save_top_k=1,\n","            mode='min',\n","            save_last=True\n","        )\n","\n","        early_stop_callback = EarlyStopping(\n","           monitor='val_loss',\n","           patience=7,\n","           verbose=True,\n","           mode='min'\n","        )\n","\n","        trainer = pl.Trainer(\n","            max_epochs=EPOCHS,\n","            accelerator=\"gpu\",\n","            devices=1,\n","            logger=csv_logger,\n","            callbacks=[checkpoint_callback, early_stop_callback],\n","            precision=\"bf16-mixed\",\n","            gradient_clip_val=1.0\n","        )\n","\n","        resume_checkpoint_path = checkpoint_dir / \"last.ckpt\"\n","        if resume_checkpoint_path.exists():\n","            print(f\"üöÄ Resuming training from checkpoint: {resume_checkpoint_path}\")\n","            trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader, ckpt_path=resume_checkpoint_path)\n","        else:\n","            print(f\"üöÄ Starting new training run for {MODEL_TO_TRAIN.upper()}...\")\n","            trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n","\n","        print(f\"‚úÖ Training complete for {MODEL_TO_TRAIN.upper()}!\")\n","        print(f\"Best model for this run saved at: {checkpoint_callback.best_model_path}\")\n","\n","    else:\n","        print(\"Dataset is too small to split. Aborting experiment.\")"],"metadata":{"id":"k8_wCYDCl2_x","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8841492255574e32857bda5015ef3710","91c3777f28754d1ba74049d5371d3b21","ef12f14512e440669d5560c56c97ae73","0aac5469ca8944d19074140c3ab66f40","4673ef3b30b24f859aebb2d9eb1df623","323a75c85fdc438785d7cd10c770e2ce","be7d561d36b8495593cca3ec94ebdcaa","40f5fe3859e14d639ba6488bee7817a8","82be8b2674114e26a5ad2fc41bab9f46","7aa113f51d924cff833b24ca60fdae4b","8fba70dd7fce4975bbd37ba257ea2768","4c1662af6e04413dacc5c7d14c391baf","f9f188afa5944d9d8b3218803840d89c","4518be4b85014a2f985961f9f28873ed","0986e35e8cb745e2be1215a634be76e4","481741a338a74b2ab3ceb1a035455706","db7daeaef7e84506847d2e4df8f45d24","6c7dbb373e5e4b22a9c93e53eefc99ff","77e2d9d247e748ac9e2db1b1593b996e","31a892fbd8b24e61ae069c66e08113a3","19eecab9db164d8a9f8aad6afcdbc55d","3afc7d2fd2f24bdab4fb40e07c2f980a","96cef4facefb4b31af529c64ac233393","68be8d9796f844a3943bd1c23e92d0ed","63285b755a7e401ebe2063a2b6398688","b411950486d742d7b05fbe7bc9cb9054","f0036b77ef0345d2a63e2c3d4e5c8d65","5084b98af2ad4e218387563773faa161","337a4f17d8384ea4bc3e7577841ba2e2","787cc22998f2444586ebe0e347ff8673","3c8d4974e2ad42be97df9c15aade0f53","973684fb761d46e7a0d3ae47fdeb1946","4f098cefdaf3453cba7431b86277cd86","93da494204db4bc1b516bf874db53f4f","8e539be8c825443d8916d018793a3adc","0677c765e572449589f0d3ded3b13962","f721df26b3204b0c9444e7d78de715d1","8eb5530b48654a788bb6945fcd36f6be","bc060510f14948cdadcf102f6fbdf77d","7dd8b26cc01c4378bf20eade31ad4e2d","1c8f1155e02347d4a4f9470037f4c988","6f84ec11c9e647d48d3414dbd9ee9a20","34b5384c6df44b4a972c5ae8fb088068","1a3064a331de4977b7086bad1f08bd20"]},"outputId":"b8226bf4-f1c1-465c-9c40-a5fd99ba1375"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Ensuring PyTorch Lightning and other libraries are installed...\n","‚úÖ Installation check complete.\n","‚úÖ Libraries imported and configuration set.\n","‚úÖ `get_model` function defined.\n","‚úÖ `SleepStageClassifierLightning` module defined.\n","‚úÖ `OptimizedCombinedDataset` class defined.\n","\n","--- Starting Swin Transformer Experiment (1000 Files, Resumable) ---\n","\n","Found 1000 specific files for training.\n","Found 1000 new or unscanned files. Scanning in batches...\n","  -> Scanning batch 1/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 2/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 3/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 4/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 5/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 6/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 7/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 8/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 9/10...\n","     ‚úÖ Saved progress for 100 files.\n","  -> Scanning batch 10/10...\n","     ‚úÖ Saved progress for 100 files.\n","‚úÖ Scan complete. Loading final metadata...\n","‚úÖ Dataset initialized. Total valid epochs: 1093021\n","Dataset split: 874416 training samples, 218605 validation samples.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8841492255574e32857bda5015ef3710","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/timm/layers/interpolate.py:47: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /pytorch/aten/src/ATen/native/BucketizationUtils.h:32.)\n","  idx_right = torch.bucketize(x, p)\n","/usr/local/lib/python3.12/dist-packages/timm/layers/interpolate.py:65: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n","  numerator += self.values[as_s] * \\\n","INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n","INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["‚úÖ Swin Transformer Base model created.\n","üöÄ Resuming training from checkpoint: /content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/last.ckpt\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:701: Checkpoint directory /content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5 exists and is not empty.\n","INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/last.ckpt\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name           | Type               | Params | Mode \n","--------------------------------------------------------------\n","0 | model          | SwinTransformer    | 86.7 M | train\n","1 | train_accuracy | MulticlassAccuracy | 0      | train\n","2 | val_accuracy   | MulticlassAccuracy | 0      | train\n","--------------------------------------------------------------\n","86.7 M    Trainable params\n","0         Non-trainable params\n","86.7 M    Total params\n","346.780   Total estimated model params size (MB)\n","465       Modules in train mode\n","0         Modules in eval mode\n","INFO:pytorch_lightning.utilities.rank_zero:Restored all states from the checkpoint at /content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/last.ckpt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c1662af6e04413dacc5c7d14c391baf","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n","/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96cef4facefb4b31af529c64ac233393","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93da494204db4bc1b516bf874db53f4f","version_major":2,"version_minor":0},"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric val_loss did not improve in the last 8 records. Best score: 0.595. Signaling Trainer to stop.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","Generating Final Performance Metrics on the Validation Set...\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# SCRIPT TO GENERATE PERFORMANCE REPORT FROM A SAVED CHECKPOINT\n","# ==============================================================================\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import pytorch_lightning as pl\n","from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os\n","\n","# --- Ensure dependencies are installed ---\n","# MODIFICATION: Pinned pyarrow to a compatible version\n","!pip install --upgrade -q pytorch-lightning timm \"pandas==2.2.2\" \"pyarrow==19.0.0\"\n","\n","# ==============================================================================\n","# 1. DEFINE THE MODEL AND DATASET CLASSES\n","#    (These must match the training script exactly)\n","# ==============================================================================\n","\n","def get_model(model_name='swin_base', num_classes=5, pretrained=True):\n","    if model_name == 'swin_base':\n","        model = timm.create_model(\n","            'swin_base_patch4_window7_224.ms_in22k',\n","            pretrained=pretrained,\n","            num_classes=num_classes,\n","            in_chans=1,\n","            img_size=(76, 60)\n","        )\n","    else:\n","        raise ValueError(f\"Model '{model_name}' not supported.\")\n","    return model\n","\n","class SleepStageClassifierLightning(pl.LightningModule):\n","    def __init__(self, model_name, learning_rate=1e-5, class_weights=None):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.model = get_model(model_name=self.hparams.model_name, num_classes=5, pretrained=False) # Pretrained=False for loading local weights\n","        self.train_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.val_accuracy = MulticlassAccuracy(num_classes=5)\n","        self.weights = torch.tensor(class_weights, dtype=torch.float) if class_weights is not None else None\n","        self.loss_fn = F.cross_entropy\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# --- MODIFICATION: Use the fast, metadata-caching dataset ---\n","class OptimizedCombinedDataset(Dataset):\n","    def __init__(self, file_paths, metadata_path):\n","        self.file_paths = file_paths\n","        self.metadata_path = metadata_path\n","        self._cache = {}\n","\n","        if os.path.exists(self.metadata_path):\n","            print(f\"Found metadata file at {self.metadata_path}. Loading epoch counts...\")\n","            metadata_df = pd.read_csv(self.metadata_path)\n","            metadata_df['filepath'] = metadata_df['filepath'].apply(Path)\n","            epoch_counts_map = dict(zip(metadata_df['filepath'], metadata_df['epoch_count']))\n","            self.epochs_per_file = [epoch_counts_map.get(fp, 0) for fp in self.file_paths]\n","            print(\"‚úÖ Epoch counts loaded from metadata file.\")\n","        else:\n","            raise FileNotFoundError(f\"Metadata file not found at {self.metadata_path}. Please run the training script first to generate it.\")\n","\n","        self.cumulative_epochs = np.cumsum(self.epochs_per_file)\n","        self.total_epochs = self.cumulative_epochs[-1] if len(self.cumulative_epochs) > 0 else 0\n","        print(f\"‚úÖ Dataset initialized. Total valid epochs: {self.total_epochs}\")\n","\n","    def __len__(self):\n","        return self.total_epochs\n","\n","    def __getitem__(self, idx):\n","        file_idx = np.searchsorted(self.cumulative_epochs, idx, side='right')\n","        local_idx = idx - (self.cumulative_epochs[file_idx - 1] if file_idx > 0 else 0)\n","        file_path = self.file_paths[file_idx]\n","        if file_path not in self._cache:\n","            try:\n","                df = pd.read_parquet(file_path)\n","                self._cache[file_path] = df[df['label'].isin([0, 1, 2, 3, 4])].reset_index(drop=True)\n","            except Exception as e:\n","                raise IOError(f\"Error reading file {file_path.name} in __getitem__: {e}\")\n","        row = self._cache[file_path].iloc[local_idx]\n","        label = np.int64(row['label'])\n","        spectrogram_flat = row.drop('label').values.astype(np.float32)\n","        mean, std = spectrogram_flat.mean(), spectrogram_flat.std()\n","        spectrogram_normalized = (spectrogram_flat - mean) / (std + 1e-6)\n","        spectrogram_2d = spectrogram_normalized.reshape(1, 76, 60)\n","        return torch.from_numpy(spectrogram_2d), torch.tensor(label)\n","\n","# ==============================================================================\n","# 2. LOAD MODEL AND DATA, THEN GENERATE REPORT\n","# ==============================================================================\n","\n","# --- CONFIGURATION ---\n","# IMPORTANT: Update this path to point to the BEST checkpoint file from the Swin Base run\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/sleep-stage-model-epoch=03-val_loss=0.5951.ckpt\"\n","METADATA_PATH = Path('/content/drive/MyDrive/dataset_metadata_1000_files.csv')\n","# -------------------\n","\n","print(f\"üß† Loading model from: {CHECKPOINT_PATH}\")\n","if not os.path.exists(CHECKPOINT_PATH):\n","    print(f\"‚ùå ERROR: Checkpoint file not found at the specified path.\")\n","else:\n","    model = SleepStageClassifierLightning.load_from_checkpoint(CHECKPOINT_PATH)\n","    model.eval()\n","    model.cuda() # Move model to GPU\n","    print(\"‚úÖ Model loaded successfully.\")\n","\n","    # --- Load the dataset (needed for the validation set) ---\n","    shhs1_processed_dir_base = Path('/content/drive/MyDrive/shhs1_processed')\n","    shhs2_processed_dir_base = Path('/content/drive/MyDrive/shhs2_processed')\n","    shhs1_files = list(shhs1_processed_dir_base.glob('*.parquet'))[:500]\n","    shhs2_files = list(shhs2_processed_dir_base.glob('*.parquet'))[:500]\n","    specific_shhs_file_paths = shhs1_files + shhs2_files\n","\n","    full_dataset = OptimizedCombinedDataset(\n","        file_paths=specific_shhs_file_paths,\n","        metadata_path=METADATA_PATH\n","    )\n","    train_size = int(0.8 * len(full_dataset))\n","    val_size = len(full_dataset) - train_size\n","    _, val_dataset = random_split(full_dataset, [train_size, val_size])\n","    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=0)\n","    print(\"‚úÖ Validation data loaded.\")\n","\n","    # --- Generate the report ---\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"Generating Final Performance Metrics on the Validation Set...\")\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            x, y = batch\n","            x = x.to(model.device)\n","            logits = model(x)\n","            preds = torch.argmax(logits, dim=1)\n","            all_preds.append(preds.cpu())\n","            all_labels.append(y.cpu())\n","    all_preds = torch.cat(all_preds)\n","    all_labels = torch.cat(all_labels)\n","\n","    num_classes = 5\n","    precision_metric = MulticlassPrecision(num_classes=num_classes, average=None)\n","    recall_metric = MulticlassRecall(num_classes=num_classes, average=None)\n","    f1_metric = MulticlassF1Score(num_classes=num_classes, average=None)\n","    accuracy_metric = MulticlassAccuracy(num_classes=num_classes, average='micro')\n","\n","    precisions = precision_metric(all_preds, all_labels)\n","    recalls = recall_metric(all_preds, all_labels)\n","    f1_scores = f1_metric(all_preds, all_labels)\n","    accuracy = accuracy_metric(all_preds, all_labels)\n","\n","    stage_map = {0: \"Wake\", 1: \"N1\", 2: \"N2\", 3: \"N3\", 4: \"REM\"}\n","    print(\"\\n--- Sleep Stage Classification Report ---\")\n","    print(f\"{'Stage':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n","    print(\"-\" * 50)\n","    for i in range(num_classes):\n","        stage_name = stage_map[i]\n","        precision, recall, f1 = precisions[i].item(), recalls[i].item(), f1_scores[i].item()\n","        print(f\"{stage_name:<10} | {precision:<10.4f} | {recall:<10.4f} | {f1:<10.4f}\")\n","    print(\"-\" * 50)\n","    print(f\"\\nOverall Accuracy: {accuracy.item():.4f}\")\n","    print(\"=\"*80 + \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"7LMjyraLjGyq","executionInfo":{"status":"error","timestamp":1756266541884,"user_tz":300,"elapsed":10562,"user":{"displayName":"Daniel Hinostroza","userId":"01416331706775365219"}},"outputId":"3926ae37-cccb-428c-c6e5-85e6b81912b5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["üß† Loading model from: /content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/sleep-stage-model-epoch=03-val_loss=0.5951.ckpt\n","‚úÖ Model loaded successfully.\n","Found metadata file at /content/drive/MyDrive/dataset_metadata_1000_files.csv. Loading epoch counts...\n","‚úÖ Epoch counts loaded from metadata file.\n","‚úÖ Dataset initialized. Total valid epochs: 1093021\n","‚úÖ Validation data loaded.\n","\n","================================================================================\n","Generating Final Performance Metrics on the Validation Set...\n"]},{"output_type":"error","ename":"OSError","evalue":"Error reading file shhs2-204275.parquet in __getitem__: module 'pyarrow.lib' has no attribute 'Decimal32Type'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3128540455.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mengine_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36minit pyarrow._parquet\u001b[0;34m()\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'pyarrow.lib' has no attribute 'Decimal32Type'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3128540455.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3128540455.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error reading file {file_path.name} in __getitem__: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocal_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Error reading file shhs2-204275.parquet in __getitem__: module 'pyarrow.lib' has no attribute 'Decimal32Type'"]}]},{"cell_type":"markdown","source":["# --- CONFIGURATION ---\n","# IMPORTANT: Update this path to point to the BEST checkpoint file from the Swin Base run\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/final_model_checkpoint/swin_base_1000_files_resumable_lr_2e-5/sleep-stage-model-epoch=03-val_loss=0.5951.ckpt\"\n","# -------------------\n"],"metadata":{"id":"dlLolO8pnBG5"}}]}