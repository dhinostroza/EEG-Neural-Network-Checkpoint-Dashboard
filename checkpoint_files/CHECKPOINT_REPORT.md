# NSSR SHHS Checkpoint Report
Generated on: 2025-12-29 23:06

Total Valid Checkpoints analyzed: 30
(Excluded 0 files marked for deletion)

## Summary Table
| Date | Model | Params (M) | Best Val Loss | Epoch | PL Ver | Filename |
|---|---|---|---|---|---|---|
| 2025-08-10 | convnextv2_tiny | 27.87M | 1.3389 | 10 | 2.5.2 | `2025-08-10_13-14_best-model-epoch=10-val_loss=1.34.ckpt` |
| 2025-08-17 | convnextv2_tiny | 27.87M | 1.3093 | 5 | 2.5.3 | `2025-08-17_21-18_final_model_lr_1e-05.ckpt` |
| 2025-08-17 | convnextv2_tiny | 27.87M | 1.5299 | 5 | 2.5.3 | `2025-08-17_21-22_final_model_lr_0_0001.ckpt` |
| 2025-08-17 | convnextv2_tiny | 27.87M | 1.5269 | 5 | 2.5.3 | `2025-08-17_21-27_final_model_lr_0_0005.ckpt` |
| 2025-08-17 | convnextv2_tiny | 27.87M | None | 19 | 2.5.3 | `2025-08-17_23-11_epoch=19-step=380.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6804 | 17 | 2.5.3 | `2025-08-23_10-44_sleep-stage-model-epoch=17-val_loss=0.6804.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6906 | 19 | 2.5.3 | `2025-08-23_11-19_sleep-stage-model-50-files-epoch=19-val_loss=0.6906.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6587 | 17 | 2.5.3 | `2025-08-23_11-43_sleep-stage-model-50-files-40-epochs-epoch=17-val_loss=0.6587.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6980 | 18 | 2.5.3 | `2025-08-23_12-32_sleep-stage-model-convnext_50_files_40_epochs_lr_1e05-epoch=18-val_loss=0.6980.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6241 | 5 | 2.5.3 | `2025-08-23_12-47_sleep-stage-model-convnext_50_files_40_epochs_lr_5e05-epoch=05-val_loss=0.6241.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.6697 | 8 | 2.5.3 | `2025-08-23_13-10_sleep-stage-model-convnext_50_files_40_epochs_lr_1e04-epoch=08-val_loss=0.6697.ckpt` |
| 2025-08-23 | Unknown | 27.87M | 0.5985 | 6 | 2.5.3 | `2025-08-23_14-32_sleep-stage-model-convnext_100_files_optimal_lr-epoch=06-val_loss=0.5985.ckpt` |
| 2025-08-23 | convnext_tiny | 27.87M | 0.5867 | 5 | 2.5.3 | `2025-08-23_15-07_sleep-stage-model-convnext_tiny_100_files_comparison-epoch=05-val_loss=0.5867.ckpt` |
| 2025-08-23 | convnext_base | 87.69M | 0.6011 | 5 | 2.5.3 | `2025-08-23_15-25_sleep-stage-model-convnext_base_100_files_comparison-epoch=05-val_loss=0.6011.ckpt` |
| 2025-08-23 | vit_base | 85.27M | 0.6536 | 3 | 2.5.3 | `2025-08-23_15-40_sleep-stage-model-vit_base_100_files_comparison-epoch=03-val_loss=0.6536.ckpt` |
| 2025-08-23 | efficientnet_b0 | 4.06M | 0.7169 | 2 | 2.5.3 | `2025-08-23_16-03_sleep-stage-model-efficientnet_b0_100_files_solo_run-epoch=02-val_loss=0.7169.ckpt` |
| 2025-08-24 | convnext_base | 87.69M | 0.8167 | 0 | 2.5.3 | `2025-08-24_22-01_sleep-stage-model-convnext_base_1000_files_resumable_lr_5e-6-epoch=00-val_loss=0.8167.ckpt` |
| 2025-08-25 | convnext_base | 87.69M | 0.6046 | 12 | 2.5.3 | `2025-08-25_01-31_sleep-stage-model-convnext_base_1000_files_resumable_lr_2e-5-epoch=12-val_loss=0.6046.ckpt` |
| 2025-08-25 | convnext_base | 87.69M | 0.6046 | 19 | 2.5.3 | `2025-08-25_04-19_last_1000_conv_next_base.ckpt` |
| 2025-08-25 | swin_base | 86.70M | 0.5951 | 3 | 2.5.3 | `2025-08-25_20-02_sleep-stage-model-epoch=03-val_loss=0.5951.ckpt` |
| 2025-08-31 | convnext_tiny | 27.87M | 0.6182 | 25 | 2.5.4 | `2025-08-31_09-18_sleep-stage-model-convnext_tiny_200_files_single_test-epoch=25-val_loss=0.6182.ckpt` |
| 2025-08-31 | convnext_tiny | 27.87M | 0.6432 | 4 | 2.5.4 | `2025-08-31_22-11_sleep-stage-convnext_tiny_gcs_500_file_test_tuned-epoch=04-val_loss=0.6432.ckpt` |
| 2025-09-02 | convnext_base | 87.69M | 0.5837 | 2 | 2.5.4 | `2025-09-02_06-44_sleep-stage-convnext_base_gcs_1000_files_tuned_lr_2e-05-epoch=02-val_loss=0.5837.ckpt` |
| 2025-09-03 | convnext_base | 87.69M | 0.6145 | 2 | 2.5.4 | `2025-09-03_17-53_best-model_convnext_base_2000files_lr2e-05_cwN1-8.0.ckpt` |
| 2025-09-04 | convnext_base | 87.69M | 0.5533 | 3 | 2.5.4 | `2025-09-04_05-36_best-model_convnext_base_2000files_lr2e-05_cwN1-8.0_workers2.ckpt` |
| 2025-09-09 | convnext_base | 87.69M | 0.6349 | 6 | 2.5.5 | `2025-09-09_15-43_best-model_convnext_base_2000files_Augmented_cwN1-6.5.ckpt` |
| 2025-09-16 | convnext_base | 87.69M | 0.6061 | 2 | 2.5.5 | `2025-09-16_12-59_best-model_convnext_base_consolidated_cwN1-6.5.ckpt` |
| 2025-09-17 | convnext_base | 87.69M | 0.6012 | 3 | 2.5.5 | `2025-09-17_19-29_best-model_convnext_base_consolidated_cwN1-6.5.ckpt` |
| 2025-09-18 | convnext_base | 87.69M | 0.6213 | 0 | 2.5.5 | `2025-09-18_20-24_best-model_convnext_base_consolidated_cwN1-6.5.ckpt` |
| 2025-09-19 | convnext_base | 87.69M | 0.5971 | 3 | 2.5.5 | `2025-09-19_04-34_best-model_convnext_base_consolidated_cwN1-6.5.ckpt` |

## Detailed Reports
### 1. 2025-08-10_13-14_best-model-epoch=10-val_loss=1.34.ckpt
- **Date**: 2025-08-10
- **Model Architecture**: convnextv2_tiny
- **Parameters**: 27.87 Million (27,867,269)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.2
- **Training Status**: Epoch 10, Step 31460
- **Best Val Loss**: 1.3389
- **Hyperparameters**:
  - `model_name`: convnextv2_tiny
  - `num_classes`: 5
  - `learning_rate`: 0.0001
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 2. 2025-08-17_21-18_final_model_lr_1e-05.ckpt
- **Date**: 2025-08-17
- **Model Architecture**: convnextv2_tiny
- **Parameters**: 27.87 Million (27,867,269)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 95
- **Best Val Loss**: 1.3093
- **Hyperparameters**:
  - `model_name`: convnextv2_tiny
  - `num_classes`: 5
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 3. 2025-08-17_21-22_final_model_lr_0_0001.ckpt
- **Date**: 2025-08-17
- **Model Architecture**: convnextv2_tiny
- **Parameters**: 27.87 Million (27,867,269)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 95
- **Best Val Loss**: 1.5299
- **Hyperparameters**:
  - `model_name`: convnextv2_tiny
  - `num_classes`: 5
  - `learning_rate`: 0.0001
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 4. 2025-08-17_21-27_final_model_lr_0_0005.ckpt
- **Date**: 2025-08-17
- **Model Architecture**: convnextv2_tiny
- **Parameters**: 27.87 Million (27,867,269)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 95
- **Best Val Loss**: 1.5269
- **Hyperparameters**:
  - `model_name`: convnextv2_tiny
  - `num_classes`: 5
  - `learning_rate`: 0.0005
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 5. 2025-08-17_23-11_epoch=19-step=380.ckpt
- **Date**: 2025-08-17
- **Model Architecture**: convnextv2_tiny
- **Parameters**: 27.87 Million (27,867,269)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 19, Step 380
- **Best Val Loss**: None
- **Hyperparameters**:
  - `model_name`: convnextv2_tiny
  - `num_classes`: 5
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 6. 2025-08-23_10-44_sleep-stage-model-epoch=17-val_loss=0.6804.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 17, Step 1314
- **Best Val Loss**: 0.6804
- **Hyperparameters**:
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 7. 2025-08-23_11-19_sleep-stage-model-50-files-epoch=19-val_loss=0.6906.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 19, Step 3540
- **Best Val Loss**: 0.6906
- **Hyperparameters**:
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 8. 2025-08-23_11-43_sleep-stage-model-50-files-40-epochs-epoch=17-val_loss=0.6587.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 17, Step 3186
- **Best Val Loss**: 0.6587
- **Hyperparameters**:
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 9. 2025-08-23_12-32_sleep-stage-model-convnext_50_files_40_epochs_lr_1e05-epoch=18-val_loss=0.6980.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 18, Step 3363
- **Best Val Loss**: 0.6980
- **Hyperparameters**:
  - `learning_rate`: 1e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 10. 2025-08-23_12-47_sleep-stage-model-convnext_50_files_40_epochs_lr_5e05-epoch=05-val_loss=0.6241.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 1062
- **Best Val Loss**: 0.6241
- **Hyperparameters**:
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 11. 2025-08-23_13-10_sleep-stage-model-convnext_50_files_40_epochs_lr_1e04-epoch=08-val_loss=0.6697.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 8, Step 1593
- **Best Val Loss**: 0.6697
- **Hyperparameters**:
  - `learning_rate`: 0.0001
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 12. 2025-08-23_14-32_sleep-stage-model-convnext_100_files_optimal_lr-epoch=06-val_loss=0.5985.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: Unknown
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 6, Step 1806
- **Best Val Loss**: 0.5985
- **Hyperparameters**:
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 13. 2025-08-23_15-07_sleep-stage-model-convnext_tiny_100_files_comparison-epoch=05-val_loss=0.5867.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: convnext_tiny
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 2094
- **Best Val Loss**: 0.5867
- **Hyperparameters**:
  - `model_name`: convnext_tiny
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 14. 2025-08-23_15-25_sleep-stage-model-convnext_base_100_files_comparison-epoch=05-val_loss=0.6011.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 5, Step 2094
- **Best Val Loss**: 0.6011
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 15. 2025-08-23_15-40_sleep-stage-model-vit_base_100_files_comparison-epoch=03-val_loss=0.6536.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: vit_base
- **Parameters**: 85.27 Million (85,267,978)
- **File Size**: 976.00 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 3, Step 1396
- **Best Val Loss**: 0.6536
- **Hyperparameters**:
  - `model_name`: vit_base
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 16. 2025-08-23_16-03_sleep-stage-model-efficientnet_b0_100_files_solo_run-epoch=02-val_loss=0.7169.ckpt
- **Date**: 2025-08-23
- **Model Architecture**: efficientnet_b0
- **Parameters**: 4.06 Million (4,055,447)
- **File Size**: 46.39 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 2, Step 774
- **Best Val Loss**: 0.7169
- **Hyperparameters**:
  - `model_name`: efficientnet_b0
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 17. 2025-08-24_22-01_sleep-stage-model-convnext_base_1000_files_resumable_lr_5e-6-epoch=00-val_loss=0.8167.ckpt
- **Date**: 2025-08-24
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,829)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 0, Step 3416
- **Best Val Loss**: 0.8167
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 5e-06
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 18. 2025-08-25_01-31_sleep-stage-model-convnext_base_1000_files_resumable_lr_2e-5-epoch=12-val_loss=0.6046.ckpt
- **Date**: 2025-08-25
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,829)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 12, Step 8867
- **Best Val Loss**: 0.6046
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 19. 2025-08-25_04-19_last_1000_conv_next_base.ckpt
- **Date**: 2025-08-25
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,829)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 19, Step 10162
- **Best Val Loss**: 0.6046
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 20. 2025-08-25_20-02_sleep-stage-model-epoch=03-val_loss=0.5951.ckpt
- **Date**: 2025-08-25
- **Model Architecture**: swin_base
- **Parameters**: 86.70 Million (86,695,037)
- **File Size**: 992.54 MB
- **PL Version**: 2.5.3
- **Training Status**: Epoch 3, Step 740
- **Best Val Loss**: 0.5951
- **Hyperparameters**:
  - `model_name`: swin_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 21. 2025-08-31_09-18_sleep-stage-model-convnext_tiny_200_files_single_test-epoch=25-val_loss=0.6182.ckpt
- **Date**: 2025-08-31
- **Model Architecture**: convnext_tiny
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.4
- **Training Status**: Epoch 25, Step 4810
- **Best Val Loss**: 0.6182
- **Hyperparameters**:
  - `model_name`: convnext_tiny
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 3.5, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 22. 2025-08-31_22-11_sleep-stage-convnext_tiny_gcs_500_file_test_tuned-epoch=04-val_loss=0.6432.ckpt
- **Date**: 2025-08-31
- **Model Architecture**: convnext_tiny
- **Parameters**: 27.87 Million (27,867,274)
- **File Size**: 319.15 MB
- **PL Version**: 2.5.4
- **Training Status**: Epoch 4, Step 8875
- **Best Val Loss**: 0.6432
- **Hyperparameters**:
  - `model_name`: convnext_tiny
  - `learning_rate`: 5e-05
  - `class_weights`: [0.7, 8.0, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 23. 2025-09-02_06-44_sleep-stage-convnext_base_gcs_1000_files_tuned_lr_2e-05-epoch=02-val_loss=0.5837.ckpt
- **Date**: 2025-09-02
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.4
- **Training Status**: Epoch 2, Step 10671
- **Best Val Loss**: 0.5837
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 5.0, 0.5, 1.5, 1.2]
- **Optimizer**: State dictionary present (1 optimizer(s))

### 24. 2025-09-03_17-53_best-model_convnext_base_2000files_lr2e-05_cwN1-8.0.ckpt
- **Date**: 2025-09-03
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.4
- **Training Status**: Epoch 2, Step 20817
- **Best Val Loss**: 0.6145
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 8.0, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 25. 2025-09-04_05-36_best-model_convnext_base_2000files_lr2e-05_cwN1-8.0_workers2.ckpt
- **Date**: 2025-09-04
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.4
- **Training Status**: Epoch 3, Step 27756
- **Best Val Loss**: 0.5533
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 8.0, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 26. 2025-09-09_15-43_best-model_convnext_base_2000files_Augmented_cwN1-6.5.ckpt
- **Date**: 2025-09-09
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.5
- **Training Status**: Epoch 6, Step 43820
- **Best Val Loss**: 0.6349
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 6.5, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 27. 2025-09-16_12-59_best-model_convnext_base_consolidated_cwN1-6.5.ckpt
- **Date**: 2025-09-16
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.5
- **Training Status**: Epoch 2, Step 85482
- **Best Val Loss**: 0.6061
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 6.5, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 28. 2025-09-17_19-29_best-model_convnext_base_consolidated_cwN1-6.5.ckpt
- **Date**: 2025-09-17
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.5
- **Training Status**: Epoch 3, Step 113976
- **Best Val Loss**: 0.6012
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 6.5, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 29. 2025-09-18_20-24_best-model_convnext_base_consolidated_cwN1-6.5.ckpt
- **Date**: 2025-09-18
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.5
- **Training Status**: Epoch 0, Step 28494
- **Best Val Loss**: 0.6213
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 6.5, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))

### 30. 2025-09-19_04-34_best-model_convnext_base_consolidated_cwN1-6.5.ckpt
- **Date**: 2025-09-19
- **Model Architecture**: convnext_base
- **Parameters**: 87.69 Million (87,693,834)
- **File Size**: 1004.03 MB
- **PL Version**: 2.5.5
- **Training Status**: Epoch 3, Step 113976
- **Best Val Loss**: 0.5971
- **Hyperparameters**:
  - `model_name`: convnext_base
  - `learning_rate`: 2e-05
  - `class_weights`: [0.7, 6.5, 0.5, 1.5, 1.2]
  - `epochs`: 40
- **Optimizer**: State dictionary present (1 optimizer(s))
